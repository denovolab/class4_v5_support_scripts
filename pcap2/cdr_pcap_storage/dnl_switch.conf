[pcapstorage]
STORAGE_TYPE = local
VOICE_PORT = 5060
VOICE_IPS = 
STORAGE_DIR = pcap
FTP_USER = pcap
FTP_PORT = 21
FTP_PASS = password
FTP_HOST = 127.0.0.1
[cdrstorage]
STORAGE_TYPE_CDR = local
STORAGE_DIR_CDR = cdr
FTP_USER_CDR = cdr
FTP_PORT_CDR = 21
FTP_PASS_CDR = password
FTP_HOST_CDR = 127.0.0.1
# Move CDR packs to remote storage if older than `CDR_KEEP_DAYS` days.
CDR_KEEP_DAYS = 15
# Pack CDR files if older than `CDR_ARCHIVE_DAYS` days.
CDR_ARCHIVE_DAYS = 30
[pcap]
CDR_SUPPORT = disabled
GCS_SUPPORT = disabled
SFTP_SUPPORT = disabled
LOG_DIR = /var/tmp
LOG_FILE = /var/tmp/pcaploaderd.log
UI_ips = 127.0.0.1
tshark = /usr/sbin/tshark
lzcat = /usr/bin/lzcat
PCAP_DIR = %(home)s/pcap2/tmppcap/
STAGING_DIR = %(home)s/pcap2/tmp/
WEB_PUBLIC_DIR = %(home)s/pcap2/wwwpub/
WEB_PUBLIC_URL = 127.0.0.1:8000/api/v1.0/wwwpub/
# not used pcap maxmum call duration (in seconds)
DURATION_LIMIT = 600
# When searching for pcap one should look for `DURATION_MARGIN`
# seconds after the call is ended to make sure have full call flow.
DURATION_MARGIN = 60
# New! Cooldown time, also check for new query period.
SLEEP_TIME = 60
API_PATH = %(home)s/pcap2
# The only needed for an SQLite setup parameters are DB_API, DB_PCAP, DB_CDR.
# The others are left for a PostgreSQL setup backward compatibility.
# DB_API can be = sqlite or = pgsql.
DB_API = sqlite
# pcap database (scheme) name
DB_PCAP = %(home)s/pcap2/pcap_db
# database username
DB_USER = pcap_db
# database hostname
DB_HOST = 127.0.0.1
# database password
DB_PASSWORD = qwerty
[loader]
TCPDUMP_DIR = %(home)s/pcap2/tcpdumpdir/
TCPDUMP_USER = denovo
tcpdump = /usr/sbin/tcpdump
TCPDUMP_STOP = no
lsof = /usr/sbin/lsof
# The loaderd turned to use pool with not more than `UPLOADERS_POOL` processes.
UPLOADERS_POOL = 4
INDEXFILE = %(home)s/testindex
INDEXPREFIX = /mnt/ftp_cdrbackup/192.168.1.1/cdr
INDEXMOUNT = curlftpfs -o allow_other <login>:<pass>@<server> /mnt/ftp/
INDEXUMOUNT = umount /mnt/ftp/
# MAX_FILES_CYCLE is a limit of files to process at single cycle, one run.
MAX_FILES_CYCLE = 100
# The time the command is allowed to spend. Used now only in get_pid().
COMMAND_TIMEOUT = 600.0
# Instruct script to skip files earlier than
# `SKIP_PCAP_NEWER_SECONDS` seconds ago.
SKIP_PCAP_NEWER_SECONDS = 180
[cdr]
tar = /usr/bin/tar
mawk = /usr/bin/mawk
CDR_DIR = /opt/switch/dnl_softswitch/cdr
CDR_SUPPORT = enabled
STORAGE_DIR_CDR = cdr
STAGING_DIR_CDR = %(home)s/pcap2/tmp_cdr/
# The only needed for an SQLite setup parameters are DB_API, DB_PCAP, DB_CDR.
# The others are left for a PostgreSQL setup backward compatibility.
# DB_API can be = sqlite or = pgsql.
DB_API_CDR = sqlite
# cdr database (scheme) name
DB_CDR = %(home)s/pcap2/cdr_db
# database username
DB_CDR_USER = pcap_db
# database hostname
DB_CDR_HOST = 127.0.0.1
# database password
DB_CDR_PASSWORD = qwerty
#class 4 v5 simple CDR header New Column set = new, Old Column = old.
CDR_HEADER = new
[cdrsmtp]
MAIL_USER = test@gmail.com
MAIL_PASS = test
MAIL_HOST = smtp.gmail.com
MAIL_PORT = 587
CDR_SUBJECT = CDR parsing completed
CDR_BODY = <b> CDR parsing </b> {from_time} {to_time}<br>search filter {
    search_parameter}<br>completed with status {status}.<br>URL is {url}.
[billingpgsql]
BILLPGSQL_HOST = 127.0.0.1
BILLPGSQL_DB = sofswitch4v5
BILLPGSQL_PASSWORD =
BILLPGSQL_USER = postgres
[pcapparsd]
# Absolute log file path.
LOG_FILE = /var/tmp/pcapparsd.log
# Maximum log size in bytes before rotate.
LOG_MAX_BYTES = 1047000
# Number of log rotation pages.
LOG_BACKUP_COUNT = 30
# LOG_LEVEL: only CRITICAL=50, all DEBUG = 10,
# all and subprocess creating multiprocessing.SUBDEBUG = 5
LOG_LEVEL = 50
[loaderd]
# Absolute log file path.
LOG_FILE = /var/tmp/loaderd.log
# Maximum log size in bytes before rotate.
LOG_MAX_BYTES = 1047000
# Number of log rotation pages.
LOG_BACKUP_COUNT = 30
# LOG_LEVEL: only CRITICAL=50, all DEBUG = 10,
#all and subprocess creating multiprocessing.SUBDEBUG = 5
LOG_LEVEL = 50
[cdrparsd]
# Absolute log file path.
LOG_FILE = /var/tmp/cdrparsd.log
# Maximum log size in bytes before rotate.
LOG_MAX_BYTES = 1047000
# Number of log rotation pages.
LOG_BACKUP_COUNT = 30
# LOG_LEVEL: only CRITICAL=50, all DEBUG = 10,
#all and subprocess creating multiprocessing.SUBDEBUG = 5
LOG_LEVEL = 50
